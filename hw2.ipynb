{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import tensorflow.keras.Input as Input\n",
    "from utils import *\n",
    "import os\n",
    "import pathlib\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import datetime\n",
    "import PIL.Image\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Input\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/szymon/Documents/Programowanie/compvis-hw/assignment_2/CompVisData\"\n",
    "training_data = \"/train2/\"\n",
    "val_data = \"/val/\"\n",
    "test_data = \"/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINSET_SIZE = len(glob.glob(dataset_path + training_data + \"*.png\"))\n",
    "print(f\"The Training Dataset contains {TRAINSET_SIZE} images.\")\n",
    "\n",
    "VALSET_SIZE = len(glob.glob(dataset_path + val_data + \"*.png\"))\n",
    "print(f\"The Validation Dataset contains {VALSET_SIZE} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "SEED = 42\n",
    "N_CHANNELS = 3\n",
    "INPUT_SHAPE = (256,256,3)\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "N_CLASSES = 15\n",
    "STEPS_PER_EPOCH = TRAINSET_SIZE // BATCH_SIZE\n",
    "VALIDATION_STEPS = VALSET_SIZE // BATCH_SIZE\n",
    "dropout_rate = 0.5\n",
    "initializer = 'he_normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(datapoint: dict) -> tuple:\n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def load_image_test(datapoint: dict) -> tuple:\n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.list_files(dataset_path + training_data + \"train_img*.png\", seed=SEED)\n",
    "train_dataset = train_dataset.map(parse_image)\n",
    "\n",
    "val_dataset = tf.data.Dataset.list_files(dataset_path + val_data + \"val_img*.png\", seed=SEED)\n",
    "val_dataset =val_dataset.map(parse_image)\n",
    "\n",
    "test_dataset = tf.data.Dataset.list_files(dataset_path + test_data + \"test_img*.png\", seed=SEED)\n",
    "test_dataset =test_dataset.map(parse_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = {\"train\": train_dataset, \"val\": val_dataset, \"test\":test_dataset}\n",
    "\n",
    "# -- Train Dataset --#\n",
    "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
    "dataset['train'] = dataset['train'].repeat()\n",
    "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
    "dataset['train'] = dataset['train'].prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "#-- Validation Dataset --#\n",
    "dataset['val'] = dataset['val'].map(load_image_test)\n",
    "dataset['val'] = dataset['val'].repeat()\n",
    "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
    "dataset['val'] = dataset['val'].prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "#-- Test Dataset --#\n",
    "dataset['test'] = dataset['test'].map(load_image_test)\n",
    "dataset['test'] = dataset['test'].repeat()\n",
    "dataset['test'] = dataset['test'].batch(BATCH_SIZE)\n",
    "dataset['test'] = dataset['test'].prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(dataset['train'])\n",
    "print(dataset['val'])\n",
    "print(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(display_list):\n",
    "    \"\"\"Show side-by-side an input image,\n",
    "    the ground truth and the prediction.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(18, 18))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "for image, mask in dataset['test'].take(1):\n",
    "    sample_image, sample_mask = image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sample([sample_image[10], sample_mask[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "EPOCHS = 5\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "callbacks = [\n",
    "    # to show samples after each epoch\n",
    "    DisplayCallback(),\n",
    "    # to collect some useful metrics and visualize them in tensorboard\n",
    "    tensorboard_callback,\n",
    "    # if no accuracy improvements we can stop the training directly\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    # to save checkpoints\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model_unet.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "# model = tf.keras.Model(inputs = inputs, outputs = output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Simple architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "simple_inputs = Input(shape=INPUT_SHAPE)\n",
    "# A convolution block\n",
    "simple_conv_enc_1 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer=initializer)(simple_inputs)\n",
    "simple_conv_enc_2 = Conv2D(256, 3, activation = 'relu', padding='same', kernel_initializer=initializer)(simple_conv_enc_1)\n",
    "# Block encoder 2\n",
    "simple_max_pool_enc_2 = MaxPooling2D(pool_size=(1, 1))(simple_conv_enc_2)\n",
    "simple_conv_enc_2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(simple_max_pool_enc_2)\n",
    "simple_conv_enc_3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(simple_conv_enc_2)\n",
    "simple_output = Conv2D(3, 1, activation = 'softmax')(simple_conv_enc_3)\n",
    "\n",
    "\n",
    "simple_model = tf.keras.Model(inputs=simple_inputs, outputs=simple_output)\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.compile(optimizer=Adam(learning_rate=0.0001), loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "simple_model_history = simple_model.fit(dataset['test'], epochs=EPOCHS,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    validation_steps=VALIDATION_STEPS,\n",
    "                    validation_data=dataset['val'],\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Complex architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = 'he_normal'\n",
    "\n",
    "# -- Encoder -- #\n",
    "# Block encoder 1\n",
    "inputs = Input(shape=INPUT_SHAPE)\n",
    "conv_enc_1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer=initializer)(inputs)\n",
    "conv_enc_1 = Conv2D(64, 3, activation = 'relu', padding='same', kernel_initializer=initializer)(conv_enc_1)\n",
    "\n",
    "# Block encoder 2\n",
    "max_pool_enc_2 = MaxPooling2D(pool_size=(2, 2))(conv_enc_1)\n",
    "conv_enc_2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(max_pool_enc_2)\n",
    "conv_enc_2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_enc_2)\n",
    "\n",
    "# Block  encoder 3\n",
    "max_pool_enc_3 = MaxPooling2D(pool_size=(2, 2))(conv_enc_2)\n",
    "conv_enc_3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(max_pool_enc_3)\n",
    "conv_enc_3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_enc_3)\n",
    "\n",
    "# Block  encoder 4\n",
    "max_pool_enc_4 = MaxPooling2D(pool_size=(2, 2))(conv_enc_3)\n",
    "conv_enc_4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(max_pool_enc_4)\n",
    "conv_enc_4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_enc_4)\n",
    "# -- Encoder -- #\n",
    "\n",
    "# ----------- #\n",
    "maxpool = MaxPooling2D(pool_size=(2, 2))(conv_enc_4)\n",
    "conv = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(maxpool)\n",
    "conv = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv)\n",
    "# ----------- #\n",
    "\n",
    "# -- Decoder -- #\n",
    "# Block decoder 1\n",
    "up_dec_1 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv))\n",
    "merge_dec_1 = concatenate([conv_enc_4, up_dec_1], axis = 3)\n",
    "conv_dec_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_1)\n",
    "conv_dec_1 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_1)\n",
    "\n",
    "# Block decoder 2\n",
    "up_dec_2 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv_dec_1))\n",
    "merge_dec_2 = concatenate([conv_enc_3, up_dec_2], axis = 3)\n",
    "conv_dec_2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_2)\n",
    "conv_dec_2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_2)\n",
    "\n",
    "# Block decoder 3\n",
    "up_dec_3 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv_dec_2))\n",
    "merge_dec_3 = concatenate([conv_enc_2, up_dec_3], axis = 3)\n",
    "conv_dec_3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_3)\n",
    "conv_dec_3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_3)\n",
    "\n",
    "# Block decoder 4\n",
    "up_dec_4 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = initializer)(UpSampling2D(size = (2,2))(conv_dec_3))\n",
    "merge_dec_4 = concatenate([conv_enc_1, up_dec_4], axis = 3)\n",
    "conv_dec_4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(merge_dec_4)\n",
    "conv_dec_4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_4)\n",
    "conv_dec_4 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = initializer)(conv_dec_4)\n",
    "# -- Dencoder -- #\n",
    "\n",
    "output = Conv2D(N_CLASSES, 1, activation = 'softmax')(conv_dec_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs = inputs, outputs = output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_history = model.fit(dataset['train'], epochs=2,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    validation_steps=VALIDATION_STEPS,\n",
    "                    validation_data=dataset['val'],\n",
    "                    callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a893c27a9ac7da36731c1c3b7293e4e0216dbef33ec69ad58d63fa40ce12a09d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
